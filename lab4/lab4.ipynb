{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNLP: Lab Session 4\n",
    "\n",
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages used for this lab\n",
    "\n",
    "import nltk, cky\n",
    "\n",
    "# Import nltk.tree and nltk.CFG\n",
    "from nltk import tree, CFG\n",
    "\n",
    "from cky import CKY, tokenise\n",
    "\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import lab4_fix\n",
    "from lab4_fix import parse_grammar\n",
    "\n",
    "from nltk.app import rdparser_app as rd\n",
    "\n",
    "\n",
    "def app(grammar,sent=\"we sleep\"):\n",
    "    \"\"\"\n",
    "    Create a recursive descent parser demo, using a simple grammar and\n",
    "    text.\n",
    "    \"\"\"\n",
    "    rd.RecursiveDescentApp(grammar, sent.split()).mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "\n",
    "The aims of this lab session are to introduce simple parser models and Context Free Grammars (CFGs) and to\n",
    "explore and address the problem of syntactic ambiguity. By the end of this lab session, you should be able to:\n",
    "\n",
    "* Access parsed treebank corpora provided in NLTK\n",
    "* Step through the process of parsing a simple sentence using a simple CFG\n",
    "* Understand why ambiguity can be a problem for parsing\n",
    "* Implement simple models to resolve the problem of ambiguity\n",
    "* Interpret a dependency parse and its relationship to a constituency parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This lab will introduce parsed corpora, parsing new data, the problems of ambiguity and syntactic agreement,\n",
    "and using features to improve parsing.\n",
    "\n",
    "#  Parsed Corpora\n",
    "\n",
    "NLTK contains a number of corpora with parse trees already available – that is, someone has already trained a\n",
    "parser and produced parse trees for each sentence in the corpus. The Penn Treebank is an example of a parsed\n",
    "corpus. It contains several sub-corpora including the Wall Street Journal (WSJ) corpus, and uses the following\n",
    "tagset: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "Import the portion of the WSJ corpus provided in NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "# The treebank contains 199 articles:\n",
    "len(treebank.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each article contains a number of sentences, each of which has been parsed. The parsed sentences are provided\n",
    "as a list of trees. Print out the first sentence of the first article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)\n",
    "# We can use nltk.tree to draw the trees, making them easier to read:\n",
    "from nltk import tree\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Now close the window to return the prompt in the terminal window)\n",
    "There are many more things that can be done with nltk.tree. The source code contains a “demo” section\n",
    "which outlines some of these things. If you are interested in learning more about nltk.tree please visit:\n",
    "http://www.nltk.org/_modules/nltk/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches to parsing CFGs\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Look at the code for Exercise 1 in lab4.py and make sure that you understand what each step does. Ask the\n",
    "lab demonstrator if you are unsure.\n",
    "Now uncomment the call to test1, load the file into python and follow the instructions overleaf:\n",
    "\n",
    "* Look at the grammar rules that are printed to the terminal window\n",
    "* Interactively step through the parsing of a sample sentence in the “app” window that pops up. Once the app window loads up:\n",
    "  - Click on “Edit” in the menu bar and select “Edit Text”\n",
    "  - Enter “I shot an elephant in my pyjamas” in the text box\n",
    "  - Click on “OK”\n",
    "  - Click the “Autostep” button and watch the parser step through\n",
    "  - Do you notice a problem?\n",
    "  - Click the “Autostep” button again to freeze the animation\n",
    "\n",
    "Amend the grammar in Exercise 1 to replace the line: NP → Det N | NP PP | ’I’\n",
    "with: NP → Det N | Det N PP | ’I’\n",
    "\n",
    "Now re-run the parser using the new grammar.\n",
    "\n",
    "**Question:** Can you explain why the parser is now able to parse the sentence?\n",
    "\n",
    "Don’t reset or close the parser app just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(grammar):\n",
    "    return CFG.fromstring(grammar)\n",
    "\n",
    "#################### EXERCISE 1 ####################\n",
    "\n",
    "# Solution for exercise 1\n",
    "# Input: none\n",
    "# Output: none\n",
    "def ex1():\n",
    "    # Load the CFG grammar\n",
    "    grammar = parse_cfg(\"\"\"\n",
    "        S -> NP VP\n",
    "        PP -> P NP\n",
    "        NP -> Det N | Det N PP | 'I'\n",
    "        VP -> V NP | VP PP\n",
    "        Det -> 'an' | 'my'\n",
    "        N -> 'elephant' | 'pyjamas'\n",
    "        V -> 'shot'\n",
    "        P -> 'in'\n",
    "        \"\"\")\n",
    "\n",
    "    # Print out the grammar rules, one line at a time\n",
    "    # pp is a method in the \"parse\" module\n",
    "    print \"Grammar rules:\"\n",
    "    pp(grammar.productions())\n",
    "\n",
    "    # Step through the parse (using a Recursive Descent / Top-down parser)\n",
    "    print \"Running interactive Recursive-Descent parser...\"\n",
    "    print \"  Close the window to end execution\"\n",
    "    app(grammar)\n",
    "    \n",
    "\n",
    "### Run to test excericse 1\n",
    "### Look in the terminal window to see the list of grammar rules\n",
    "### In the pop-up window, do the following:\n",
    "###    Click on \"Edit\" in the menu bar and select \"Edit Text\"\n",
    "###    Enter \"I shot an elephant in my pyjamas\" in the text box\n",
    "###    Click on \"OK\"\n",
    "###    Click the \"Autostep\" button and watch the parser step through\n",
    "###    Do you notice a problem?\n",
    "###    Click the \"Autostep\" button again to freeze the animation\n",
    "ex1()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiguity\n",
    "\n",
    "But, getting the grammar right isn’t our only problem. The sentence “I shot an elephant in my pyjamas” is\n",
    "also ambiguous. Consider who is wearing the pyjamas – the elephant or the person doing the shooting.\n",
    "\n",
    "You can see this by forcing the demo parser to backtrack and look for another parse: just click autostep after\n",
    "it has found the first parse.\n",
    "\n",
    "Here are the two possible parses of this sentence, depending on who is wearing the “pyjamas”, and arising from\n",
    "structural ambiguity surrounding PP attachment:\n",
    "\n",
    "\n",
    "```\n",
    "                                                            S\n",
    "                                                          /   \\\n",
    "(S                                                       /     \\\n",
    "  (NP I)                                                NP     VP  \n",
    "  (VP                                                   |    /    \\\n",
    "     (V shot)                                           I   /      \\\n",
    "         (NP (Det an) (N elephant)                         /        \\\n",
    "         (PP (P in) (NP (Det my) (N pyjamas)))))          VP         PP\n",
    "                                                         /  \\      /    \\\n",
    "                                                        /    \\    /      \\\n",
    "                                                       Vt    NP   P      NP  \n",
    "                                                       |    /  \\  |     /  \\\n",
    "                                                     shot Det  N in   Det  N\n",
    "                                                           |   |       |   |\n",
    "                                                          an elephant my pyjamas\n",
    "\n",
    "\n",
    "                                                                    \n",
    "                                                      S\n",
    "(S                                                  /   \\ \n",
    "  (NP I)                                           /     \\\n",
    "  (VP                                            NP       VP\n",
    "     (VP (V shot) (NP (Det an) (N elephant)))    |      /   \\\n",
    "     (PP (P in) (NP (Det my) (N pyjamas)))))     I     /     \\\n",
    "                                                     Vt       NP\n",
    "                                                      |     /     \\\n",
    "                                                     shot  /       \\\n",
    "                                                         NP         PP\n",
    "                                                       /    \\      /  \\\n",
    "                                                     Det     N    P   NP  \n",
    "                                                      |      |    |  /  \\\n",
    "                                                     an elephant in Det  N\n",
    "                                                                     |   |\n",
    "                                                                    my pyjamas\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Question**: Which parse reflects the elephant wearing the pyjamas and which reflects the person doing the\n",
    "shooting wearing the pyjamas?\n",
    "\n",
    "Now you can close the parser demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKY parsing\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "A simple CKY parser is imported from cky.py. In this exercise you will explore how it implements the CKY algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### EXERCISE 2 ####################\n",
    "\n",
    "# A somewhat more detailed grammar for Exercise 2\n",
    "grammar2=parse_grammar([\n",
    "\"S -> Sdecl '.' | Simp '.' | Sq '?' \", # Take advantage of the punctuation\n",
    "\"Sdecl -> NP VP\",\n",
    "\"Simp -> VP\",\n",
    "\"Sq -> Sqyn | Swhadv\",\n",
    "\"Sqyn -> Mod Sdecl | Aux Sdecl\", # Re-use where we can\n",
    "\"Swhadv -> WhAdv Sqyn\", # likewise\n",
    "\"Sc -> Subconj Sdecl\", # For \"that S\"\n",
    "\"NP -> PropN | Pro | NP0 \", # NP that allows no modification\n",
    "\"NP0 -> NP1 | NP0 PP\", # NP with (multiple) PP attachment\n",
    "\"NP1 -> Det N2sc | Det N2mp | N2mp | Sc\", # Common nouns and sentential complements\n",
    "\"N2sc -> Adj N2sc | Nsc | N3 Nsc\", # Adjectival mod, head noun for singular\n",
    "                                   #  count nouns\n",
    "\"N2mp -> Adj N2mp | Nmp | N3 Nmp\", # Adjectival mod, head noun for plural\n",
    "                                   #  count nouns or mass nouns\n",
    "\"N3 -> N | N3 N\", # Noun-noun compounds\n",
    "\"N -> Nsc | Nmp\",\n",
    "\"VP -> VPi | VPt | VPdt | Mod VP | VP Adv | VP PP\", # a bit of subcat,\n",
    "                                                    # allows mixed Adv and PP\n",
    "                                                    # modifications :-(\n",
    "\"VPi -> Vi\", # intransitive\n",
    "\"VPt -> Vt NP\", # transitive\n",
    "\"VPdt -> VPo PP\", # ditransitive, obligatory NP (obj.) & PP complements\n",
    "\"VPdt -> VPio NP\", # ditransitive, obligatory NP (iobj.) & NP (obj)\n",
    "\"VPo -> Vdt NP\", # direct object of ditransitive\n",
    "\"VPio -> Vdt NP\", # indirect obj. part of dative-shifted ditransitive\n",
    "\"PP -> Prep NP\",\n",
    "\"Det -> 'a' | 'the' | 'an' | 'my'\",\n",
    "\"Nmp -> 'salad' | 'mushrooms' | 'pyjamas'\",  # mass nouns, plural count nouns\n",
    "\"Nsc -> 'book' | 'fork' | 'flight' | 'salad' | 'drawing' | 'elephant'\", # singular count\n",
    "\"Prep -> 'to' | 'with' | 'in'\",\n",
    "\"Vi -> 'ate'\",\n",
    "\"Vt -> 'ate' | 'book' | 'Book' | 'gave' | 'told' | 'shot'\",\n",
    "\"Vdt -> 'gave' | 'told' \",\n",
    "\"Subconj -> 'that'\",\n",
    "\"Mod -> 'Can' | 'will'\",\n",
    "\"Aux -> 'did' \",\n",
    "\"WhAdv -> 'Why'\",\n",
    "\"PropN -> 'John' | 'Mary' | 'NYC' | 'London'\",\n",
    "\"Adj -> 'nice' | 'drawing'\",\n",
    "\"Pro -> 'you' | 'he' | 'I'\",\n",
    "\"Adv -> 'today'\"\n",
    "])\n",
    "\n",
    "chart=CKY(grammar2)\n",
    "\n",
    "def test2_1(verbose=False):\n",
    "    global chart\n",
    "    s=\"I ate salad.\"\n",
    "    chart.parse(tokenise(s),verbose)\n",
    "    print str(chart.firstTree())\n",
    "    chart.pprint()\n",
    "\n",
    "def test2_2(verbose=False):\n",
    "    global chart\n",
    "    s=\"I shot an elephant in my pyjamas.\"\n",
    "    parsed=chart.parse(tokenise(s),verbose)\n",
    "    if parsed:\n",
    "        for tree in chart.allTrees():\n",
    "            print str(tree)\n",
    "            tree.draw()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first call to `test2_1()` You’ll see both the parse and the completed CKY matrix. Look at the grammar, the matrix and the result and satisfy yourself that you know where each entry\n",
    "in the matrix comes from, and where the backpointers must be to allow the parse to be reconstructed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print \"CKY parser...\"\n",
    "### Parse a simple sentence with the CKY parser and show the resulting matrix\n",
    "test2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the second call to `test2_1()` so that the actions associated with each cell are shown. Again, inspect this\n",
    "and see that it confirms your earlier understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show what happens in each cell of the matrix during the parse\n",
    "test2_1(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `try test2_2` to go back to our ambiguous sentence. You will have to close the tree displays to get from\n",
    "one tree to the next, and to get back to the Python interpreter. You can see the underlying matrix by doing:\n",
    "    \n",
    "    chart.pprint()\n",
    "\n",
    "You can go on to try other inputs by doing:\n",
    "\n",
    "    chart.parse(tokenise(\"...\")[,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try the Groucho Marx sentence\n",
    "test2_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the matrix\n",
    "chart.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dependencies\n",
    "\n",
    "*Dependency parsing will be covered in depth in the lecture on 7 March 2017.*\n",
    "\n",
    "All the parses we’ve seen so far are constituency trees. An alternative way of representing syntactic structure\n",
    "is with a dependency tree, in which nodes are words in the sentence and edges represent head-modifier\n",
    "relationships. For instance, an unlabeled dependency parse of I only eat the best apples:\n",
    "\n",
    "```\n",
    "  eat\n",
    " / |  \\\n",
    "I only apples\n",
    "       / |\n",
    "     the best\n",
    "```\n",
    "The overall head of the sentence is typically the main verb—in this case, eat. Heads are connected by edges to their direct modifiers or arguments. Edges can further be decorated with labels indicating grammatical relations like subject, direct object, adverbial modifier, etc.\n",
    "\n",
    "Dependency parsers can produce such trees either by rule-based conversion from constituency trees, or by\n",
    "parsing directly into dependencies. The widely-used Stanford Parser is an example of the former strategy: it\n",
    "constituency-parses, then converts to dependencies.\n",
    "\n",
    "#### Exercise 3\n",
    "\n",
    "Use the online demo at http://nlp.stanford.edu:8080/corenlp/process to parse the sentence “I shot an\n",
    "elephant in my pajamas.” Look at the output displayed under “Basic Dependencies”.\n",
    "Refer to http://universaldependencies.org/en/dep/ for descriptions of the edge labels.\n",
    "Which way is the ambiguity resolved—i.e., which of the constituency parses from Exercise 2 does the Stanford\n",
    "dependency parse correspond to? How would the dependency parse differ for the other reading of the sentence?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "\n",
    "Give the productions needed for the second (‘correct’ but not funny) constituency tree from Exercise 1 (see\n",
    "section 6 above). On the right-hand side of each rule, underline the one nonterminal whose constituent contains\n",
    "the head of the rule according to the dependency parse. The first one is (Underline replaced by bold here):\n",
    "\n",
    "S → NP **VP**\n",
    "\n",
    "VP is underlined (bold) because S covers the entire sentence, and the yield of VP contains the verb, which is the overall\n",
    "head of the sentence. Do you see how identifying these head-containing constituents (achieved in practice with\n",
    "heuristics known as head rules) leads to a deterministic transformation from the constituency parse to the\n",
    "dependency parse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
